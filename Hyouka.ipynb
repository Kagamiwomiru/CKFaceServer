{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten,Input\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.applications.xception import Xception\n",
    "from keras.optimizers import SGD\n",
    "from keras import callbacks\n",
    "from keras.backend import tensorflow_backend as backend\n",
    "import keras.backend as K\n",
    "import json\n",
    "\n",
    "# 画像サイズ．ResNetを使う時は224\n",
    "img_size = 224\n",
    "batch_size = 32\n",
    "#以下ディレクトリに入っている画像を読み込む\n",
    "root_dir = \"./face/\"\n",
    "#学習データを何周するか\n",
    "epochs=50\n",
    "#ログファイル\n",
    "log_filepath=\"./logs/\"\n",
    "#学習したモデル\n",
    "ModelWeightData=\"./face/face-model.h5\"\n",
    "ModelArcData=\"./face/face.json\"\n",
    "classFile=\"./face/categories.json\"\n",
    "#学習率(SGD(lr=???))\n",
    "learning_rate=0.01\n",
    "#活性化関数\n",
    "activation='softmax'\n",
    "#重みの初期化\n",
    "kernel_init='glorot_uniform'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1135 images belonging to 12 classes.\n",
      "Found 1135 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "    #学習画像データを水増し（データ拡張）を行う\n",
    "    mizumashi_data=ImageDataGenerator(rotation_range=180,width_shift_range=0.2)\n",
    "    mizumashi_generator=mizumashi_data.flow_from_directory(directory=root_dir,target_size=(img_size,img_size),batch_size=batch_size,shuffle=True)\n",
    "    #テスト画像データを水増しする。\n",
    "    val_datagen=ImageDataGenerator(rotation_range=180,width_shift_range=0.2)\n",
    "    val_gen=val_generator=val_datagen.flow_from_directory(directory=root_dir,target_size=(img_size,img_size),batch_size=batch_size,shuffle=False)\n",
    "    valX,valy=val_gen.next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "    base_model = Xception(weights='imagenet', include_top=False,\n",
    "                         input_tensor=Input(shape=(img_size,img_size, 3)))\n",
    "   #base_model.summary()\n",
    "    x=base_model.output\n",
    "    #入力を平滑化\n",
    "    x=Flatten()(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "    predictions = Dense(mizumashi_generator.num_classes,kernel_initializer=kernel_init, activation=activation)(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    opt = SGD(lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#評価指標を定義（自分のプログラムで使用する際はこの部分をコピペすれば良い。呼び出し方法はmodel.compile(...,metrics[の部分参照])\n",
    "def Precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "\n",
    "    Only computes a batch-wise average of precision.\n",
    "\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def Recall(y_true, y_pred):\n",
    "\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "def F1(y_true, y_pred):\n",
    "    def Precision(y_true, y_pred):\n",
    "  \n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    def Recall(y_true, y_pred):\n",
    "       \n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "    precision = Precision(y_true, y_pred)\n",
    "    recall = Recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "35/35 [==============================] - 29s 824ms/step - loss: 1.5303 - acc: 0.5704 - F1: nan - Recall: 0.3747 - Precision: 0.7271 - val_loss: 0.5043 - val_acc: 0.8607 - val_F1: 0.8298 - val_Recall: 0.7598 - val_Precision: 0.9279\n",
      "Epoch 2/50\n",
      "35/35 [==============================] - 27s 779ms/step - loss: 0.2664 - acc: 0.9428 - F1: 0.9276 - Recall: 0.8847 - Precision: 0.9783 - val_loss: 0.1366 - val_acc: 0.9755 - val_F1: 0.9710 - val_Recall: 0.9529 - val_Precision: 0.9911\n",
      "Epoch 3/50\n",
      "35/35 [==============================] - 27s 785ms/step - loss: 0.1205 - acc: 0.9705 - F1: 0.9681 - Recall: 0.9544 - Precision: 0.9825 - val_loss: 0.0595 - val_acc: 0.9909 - val_F1: 0.9871 - val_Recall: 0.9801 - val_Precision: 0.9945\n",
      "Epoch 4/50\n",
      "35/35 [==============================] - 28s 788ms/step - loss: 0.0583 - acc: 0.9937 - F1: 0.9900 - Recall: 0.9866 - Precision: 0.9936 - val_loss: 0.0457 - val_acc: 0.9955 - val_F1: 0.9911 - val_Recall: 0.9828 - val_Precision: 1.0000\n",
      "Epoch 5/50\n",
      "35/35 [==============================] - 27s 783ms/step - loss: 0.0485 - acc: 0.9902 - F1: 0.9887 - Recall: 0.9839 - Precision: 0.9936 - val_loss: 0.0282 - val_acc: 0.9964 - val_F1: 0.9955 - val_Recall: 0.9946 - val_Precision: 0.9964\n",
      "Epoch 6/50\n",
      "35/35 [==============================] - 28s 792ms/step - loss: 0.0388 - acc: 0.9929 - F1: 0.9910 - Recall: 0.9893 - Precision: 0.9928 - val_loss: 0.0291 - val_acc: 0.9909 - val_F1: 0.9915 - val_Recall: 0.9873 - val_Precision: 0.9961\n",
      "Epoch 00006: early stopping\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "loss= 0.022000838071107864\n",
      "accuracy= 1.0\n",
      "F1= 1.0\n",
      "Recall 1.0\n",
      "Precision 1.0\n"
     ]
    }
   ],
   "source": [
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy',F1,Recall,Precision])\n",
    "    tb_cb=keras.callbacks.TensorBoard(log_dir=log_filepath,histogram_freq=0)\n",
    "    es_cb=keras.callbacks.EarlyStopping(monitor='val_loss',patience=0,verbose=1,mode='auto')\n",
    "    cbks=[tb_cb,es_cb]\n",
    "    history = model.fit_generator(mizumashi_generator,\n",
    "                                  validation_data=val_generator,\n",
    "                                  steps_per_epoch=mizumashi_generator.samples// batch_size,\n",
    "                                  validation_steps=val_generator.samples // batch_size,\n",
    "                                  epochs=epochs,callbacks=cbks,\n",
    "                                  verbose=1)\n",
    "    score = model.evaluate(valX, valy,batch_size=batch_size)\n",
    "    print('loss=', score[0])\n",
    "    print('accuracy=', score[1])\n",
    "    print('F1=', score[2])\n",
    "    print('Recall',score[3])\n",
    "    print('Precision',score[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo \"OK\"|/home/kagamiwomiru/notiSlack.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
